{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from accelerate import DataLoaderConfiguration\n",
    "from accelerate import Accelerator, DistributedDataParallelKwargs\n",
    "import wandb\n",
    "import torch\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = os.path.abspath('')\n",
    "\n",
    "save_dir =  os.path.join(file_dir,'train_output')\n",
    "data_dir = os.path.join(file_dir, '..','data_preprocessing','generated_data')\n",
    "\n",
    "train_utils_path = os.path.join(file_dir,'..','train_utils')\n",
    "if train_utils_path not in sys.path:\n",
    "    sys.path.append(train_utils_path)\n",
    "from utils import (\n",
    "    plot_training_loss,\n",
    "    plot_training_validation,\n",
    "    compare_motif_list\n",
    ")\n",
    "from utils_data import load_TF_data, load_TF_data_bidir, call_motif_scan\n",
    "\n",
    "universal_guide_path = os.path.join(file_dir, '..', '..','re_design', \n",
    "                                    'Universal-Guided-Diffusion', 'Guided_Diffusion_Imagenet')\n",
    "if universal_guide_path not in sys.path:\n",
    "    sys.path.append(universal_guide_path)\n",
    "\n",
    "from guided_diffusion import logger\n",
    "from guided_diffusion.resample import create_named_schedule_sampler\n",
    "\n",
    "from universal_models import (\n",
    "    create_model_and_diffusion,\n",
    "    scBPnetGuide,\n",
    ")\n",
    "\n",
    "from universal_tools import (\n",
    "    OperationArgs,\n",
    "    TrainLoop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionTrainingConfig:\n",
    "    datafile=f'{data_dir}/sampled_df_columns_renamed_bidir.csv'\n",
    "    device = 'cuda'\n",
    "    pikle_filename = \"cre_expr_bidir_512seqlength_classcond_3clusters\"\n",
    "    run_name = \"512seqlength_bidir_activecre\" # for gimme scan erros when doing several runs simultaneously \n",
    "    guide_checkpoint = \"guide_checkpoints/model_e9_b9901.pth\"\n",
    "    load_data = True\n",
    "    subset = None\n",
    "    num_workers = 4\n",
    "    seq_length=512\n",
    "    \n",
    "    batch_size=256\n",
    "    train_cond = True # whether to train conditionally\n",
    "    lr=1e-4\n",
    "    weight_decay=0.1\n",
    "    lr_anneal_steps=2000\n",
    "    \n",
    "    log_interval=20\n",
    "    sample_interval=20\n",
    "    save_interval=1000000\n",
    "    resume_checkpoint=\"\"\n",
    "    # use_fp16=False\n",
    "    # fp16_scale_growth=1e-3\n",
    "\n",
    "    # Sampling\n",
    "    # use_ddim=False\n",
    "    clip_denoised=True\n",
    "    \n",
    "    sampling_subset_random = 50 # number of cell types to subset for faster sampling\n",
    "    num_cre_counts_per_cell_type = 200\n",
    "    parallel_generating_bs = 256 # used for parallel sampling, adjust based on GPU memory capabilities\n",
    "    get_seq_metrics = False\n",
    "    get_kmer_metrics_bulk = False\n",
    "    get_kmer_metrics_labelwise = False # not implemented, takes too long\n",
    "    kmer_length = 5   \n",
    "\n",
    "    # model\n",
    "    class_cond=False\n",
    "    use_checkpoint=False # not implemented\n",
    "    image_size=seq_length\n",
    "    ema_rate=0.995\n",
    "    num_channels=256\n",
    "    num_res_blocks=2\n",
    "    num_heads=2\n",
    "    num_heads_upsample=-1\n",
    "    num_head_channels=64\n",
    "    attention_resolutions=\"\"\n",
    "    # channel_mult=\"\"\n",
    "    dropout=0.1\n",
    "    \n",
    "    use_scale_shift_norm=True\n",
    "    resblock_updown=True\n",
    "    use_new_attention_order=False\n",
    "\n",
    "    # Diffusion\n",
    "    schedule_sampler=\"uniform\" # or \"loss-second-moment\"\n",
    "    learn_sigma=True\n",
    "    diffusion_steps=100\n",
    "    noise_schedule=\"linear\" # or \"cosine\"\n",
    "    timestep_respacing=\"\"\n",
    "    sigma_small=False\n",
    "    use_kl=True\n",
    "    predict_xstart=False\n",
    "    rescale_timesteps=True\n",
    "    rescale_learned_sigmas=False\n",
    "\n",
    "    # to send config to wandb\n",
    "    @classmethod\n",
    "    def to_dict(cls):\n",
    "        return {k: v for k, v in cls.__dict__.items() if not k.startswith('__') and not callable(v) and k != 'to_dict'}\n",
    "\n",
    "\n",
    "config = DiffusionTrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_TF_data_bidir(\n",
    "    data_path=config.datafile,\n",
    "    seqlen=config.seq_length,\n",
    "    limit_total_sequences=config.subset,\n",
    "    to_save_file_name=config.pikle_filename,\n",
    "    saved_file_name=config.pikle_filename + \".pkl\",\n",
    "    load_saved_data=config.load_data,\n",
    "    train_cond = config.train_cond,\n",
    "    run_name = config.run_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "_, arr = np.unique(data['x_train_cell_type'], return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3654,  0.4050,  1.9861,  ..., -0.3083,  0.1713,  1.1925],\n",
       "        [-0.3819, -0.6687, -0.4859,  ...,  2.8117,  1.1389,  1.2058],\n",
       "        [ 2.3654,  0.4050,  1.9861,  ..., -0.3083,  0.1713,  1.1925],\n",
       "        ...,\n",
       "        [ 2.3654,  0.4050,  1.9861,  ..., -0.3083,  0.1713,  1.1925],\n",
       "        [-0.3819, -0.6687, -0.4859,  ...,  2.8117,  1.1389,  1.2058],\n",
       "        [-0.8090, -0.2480,  0.6853,  ...,  0.5333, -0.1603, -0.7974]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = torch.nn.Embedding(3,10)\n",
    "embed(torch.tensor(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26935696149822763"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_motif_list(data['train_motifs'],data['shuffle_motifs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_config:\n",
    "{'cell_state_dim': 50,\n",
    " 'ctrl_nodes': 256,\n",
    " 'ctrl_layers': 1,\n",
    " 'ctrl_outputs': 64,\n",
    " 'bp_n_filters': 512,\n",
    " 'conv_layers': 10,\n",
    " 'trimming': 512,\n",
    " 'dropout_rate': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# example_output_profile = \"matt_code/example_y.pkl\"\n",
    "# example_cell_states = \"matt_code/example_c.pkl\"\n",
    "# example_input_sequences = \"matt_code/example_X.pkl\"\n",
    "\n",
    "# with open(example_input_sequences, 'rb') as f:\n",
    "#     X = pickle.load(f)\n",
    "# with open(example_output_profile, 'rb') as f:\n",
    "#     y = pickle.load(f)\n",
    "# with open(example_cell_states, 'rb') as f:\n",
    "#     c = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vector = torch.rand((128,52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((128,1,4,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_model = scBPnetGuide(config.guide_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, diffusion = create_model_and_diffusion(config)\n",
    "schedule_sampler = create_named_schedule_sampler(config.schedule_sampler, diffusion)\n",
    "# model.to(dist_util.dev())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_config = OperationArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_config = DataLoaderConfiguration(split_batches=False)\n",
    "accelerator = Accelerator(\n",
    "            # kwargs_handlers=[ddp_kwargs],\n",
    "            dataloader_config = dataloader_config, \n",
    "            cpu= (config.device == \"cpu\"), \n",
    "            mixed_precision= None, \n",
    "            log_with=['wandb'])\n",
    "\n",
    "trainloop = TrainLoop(\n",
    "    config=config,\n",
    "    operation_config=operation_config,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guide_model=guide_model,\n",
    "    accelerator=accelerator,\n",
    "    data=data,\n",
    "    batch_size=config.batch_size,\n",
    "    lr=config.lr,\n",
    "    log_interval=config.log_interval,\n",
    "    sample_interval = config.sample_interval,\n",
    "    save_interval=config.save_interval,\n",
    "    resume_checkpoint=config.resume_checkpoint,\n",
    "    schedule_sampler=schedule_sampler,\n",
    "    lr_anneal_steps=config.lr_anneal_steps,\n",
    "    run_name = config.run_name,\n",
    ")\n",
    "# os.environ['WANDB_SILENT']=\"true\"\n",
    "# os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "# wandb_config = {\"learning_rate\": config.lr, \"num_sampling_to_compare_cells\": config.num_sampling_to_compare_cells, \"batch_size\": config.batch_size}\n",
    "# wandb.init(project=\"universal_diffusion\", config=wandb_config)\n",
    "\n",
    "# trainloop.run_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 handles 231 samples.\n"
     ]
    }
   ],
   "source": [
    "trainloop.initialize_sampling()\n",
    "a = trainloop.process_label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(331, 0.0, 0.0),\n",
       " (16, 0.0, 0.0),\n",
       " (252, 0.0, 0.0),\n",
       " (252, 0.0, 0.0),\n",
       " (285, 0.0, 0.0),\n",
       " (285, 0.0, 0.0),\n",
       " (285, 0.0, 0.0),\n",
       " (285, 0.0, 0.0),\n",
       " (334, 0.0, 0.0),\n",
       " (334, 0.0, 0.0),\n",
       " (7, 0.0, 0.0),\n",
       " (7, 0.0, 0.0),\n",
       " (116, 0.0, 0.0),\n",
       " (273, 0.0, 0.0),\n",
       " (273, 0.0, 0.0),\n",
       " (289, 0.0, 0.0),\n",
       " (162, 0.0, 0.0),\n",
       " (162, 0.0, 0.0),\n",
       " (162, 0.0, 0.0),\n",
       " (375, 0.0, 0.0),\n",
       " (375, 0.0, 0.0),\n",
       " (90, 0.0, 0.0),\n",
       " (17, 0.0, 0.0),\n",
       " (304, 0.0, 0.0),\n",
       " (288, 0.0, 0.0),\n",
       " (288, 0.0, 0.0),\n",
       " (190, 0.0, 0.0),\n",
       " (190, 0.0, 0.0),\n",
       " (190, 0.0, 0.0),\n",
       " (190, 0.0, 0.0),\n",
       " (40, 0.0, 0.0),\n",
       " (144, 0.0, 0.0),\n",
       " (431, 0.0, 0.0),\n",
       " (431, 0.0, 0.0),\n",
       " (431, 0.0, 0.0),\n",
       " (431, 0.0, 0.0),\n",
       " (431, 0.0, 0.0),\n",
       " (210, 0.6856283387397418, 0.4357586612602581),\n",
       " (22, 0.0, 0.0),\n",
       " (247, 0.0, 0.0),\n",
       " (247, 0.0, 0.0),\n",
       " (79, 0.0, 0.0),\n",
       " (79, 0.0, 0.0),\n",
       " (79, 0.0, 0.0),\n",
       " (348, 0.0, 0.0),\n",
       " (348, 0.0, 0.0),\n",
       " (348, 0.0, 0.0),\n",
       " (207, 0.0, 0.0),\n",
       " (207, 0.0, 0.0),\n",
       " (207, 0.0, 0.0),\n",
       " (224, 0.2373365954795822, 1.8384822045204177),\n",
       " (446, 0.0, 0.0),\n",
       " (446, 0.8698639379200999, 0.0682704920799001),\n",
       " (446, 0.0, 0.0),\n",
       " (446, 0.0, 0.0),\n",
       " (165, 0.813260239362615, 0.162184460637385),\n",
       " (165, 0.0, 0.0),\n",
       " (387, 0.0, 0.0),\n",
       " (387, 0.0, 0.0),\n",
       " (152, 0.0, 0.0),\n",
       " (152, 0.0, 0.0),\n",
       " (269, 0.0, 0.0),\n",
       " (269, 0.0, 0.0),\n",
       " (98, 0.0, 0.0),\n",
       " (98, 0.0, 0.0),\n",
       " (98, 0.0, 0.0),\n",
       " (395, 0.0, 0.0),\n",
       " (176, 0.0, 0.0),\n",
       " (176, 0.0, 0.0),\n",
       " (379, 0.0, 0.0),\n",
       " (211, 0.0, 0.0),\n",
       " (75, 0.0, 0.0),\n",
       " (75, 0.0, 0.0),\n",
       " (437, 0.0, 0.0),\n",
       " (138, 0.0, 0.0),\n",
       " (138, 0.0, 0.0),\n",
       " (138, 0.614825980576249, 0.908076419423751),\n",
       " (260, 0.0, 0.0),\n",
       " (260, 0.0, 0.0),\n",
       " (260, 0.0, 0.0),\n",
       " (355, 0.0, 0.0),\n",
       " (220, 0.0, 0.0),\n",
       " (220, 0.6924187545823105, 0.2556720454176895),\n",
       " (220, 0.0, 0.0),\n",
       " (220, 0.0, 0.0),\n",
       " (220, 0.0, 0.0),\n",
       " (220, 0.0, 0.0),\n",
       " (447, 0.0, 0.0),\n",
       " (447, 0.0, 0.0),\n",
       " (447, 0.0, 0.0),\n",
       " (447, 0.0, 0.0),\n",
       " (447, 0.0, 0.0),\n",
       " (447, 0.0, 0.0),\n",
       " (447, 2.036013, 0.0),\n",
       " (337, 0.0, 0.0),\n",
       " (337, 0.0, 0.0),\n",
       " (337, 0.6779776218132224, 0.4950135781867776),\n",
       " (337, 0.0, 0.0),\n",
       " (2, 0.0, 0.0),\n",
       " (136, 0.0, 0.0),\n",
       " (136, 0.0, 0.0),\n",
       " (136, 0.0, 0.0),\n",
       " (429, 0.0, 0.0),\n",
       " (108, 0.0, 0.0),\n",
       " (108, 0.0, 0.0),\n",
       " (108, 0.0, 0.0),\n",
       " (432, 0.7449736968865612, 0.2850574031134388),\n",
       " (312, 0.0, 0.0),\n",
       " (312, 0.0, 0.0),\n",
       " (213, 0.0, 0.0),\n",
       " (213, 0.0, 0.0),\n",
       " (427, 0.0, 0.0),\n",
       " (427, 0.0, 0.0),\n",
       " (427, 0.0, 0.0),\n",
       " (427, 0.0, 0.0),\n",
       " (181, 0.0, 0.0),\n",
       " (181, 0.0, 0.0),\n",
       " (181, 0.0, 0.0),\n",
       " (383, 0.0, 0.0),\n",
       " (383, 0.0, 0.0),\n",
       " (383, 2.876997208132775, 0.6888713918672249),\n",
       " (319, 0.0, 0.0),\n",
       " (319, 1.1321329264170383, 0.3547949735829617),\n",
       " (266, 0.6817780132023544, 0.6785036867976456),\n",
       " (266, 0.0, 0.0),\n",
       " (266, 0.0, 0.0),\n",
       " (266, 0.0697353755799543, 0.8257996744200458),\n",
       " (266, 0.0, 0.0),\n",
       " (266, 0.0, 0.0),\n",
       " (257, 0.0, 0.0),\n",
       " (257, 0.0, 0.0),\n",
       " (257, 0.0, 0.0),\n",
       " (277, 0.0, 0.0),\n",
       " (277, 0.0, 0.0),\n",
       " (35, 0.2269084457822958, 0.6704302542177042),\n",
       " (458, 0.0, 0.0),\n",
       " (338, 0.0, 0.0),\n",
       " (188, 0.0, 0.0),\n",
       " (188, 0.0, 0.0),\n",
       " (188, 0.0, 0.0),\n",
       " (294, 0.0, 0.0),\n",
       " (294, 0.0, 0.0),\n",
       " (88, 0.0, 0.0),\n",
       " (88, 0.0, 1.0590374),\n",
       " (128, 0.0, 0.0),\n",
       " (243, 0.0, 0.0),\n",
       " (243, 0.0, 0.0),\n",
       " (411, 0.0, 0.0),\n",
       " (411, 0.0, 0.0),\n",
       " (411, 0.0, 0.0),\n",
       " (411, 0.0, 0.0),\n",
       " (18, 0.0, 0.0),\n",
       " (18, 0.0, 0.0),\n",
       " (468, 0.0, 0.0),\n",
       " (468, 0.0, 0.0),\n",
       " (468, 0.0, 0.0),\n",
       " (292, 0.0, 0.0),\n",
       " (175, 0.0, 0.0),\n",
       " (351, 0.0, 0.0),\n",
       " (377, 0.0, 0.0),\n",
       " (38, 0.0, 0.0),\n",
       " (38, 0.0, 0.0),\n",
       " (311, 0.0, 0.0),\n",
       " (311, 0.0, 0.0),\n",
       " (311, 0.2747128834757485, 0.5561666865242514),\n",
       " (43, 0.6023616530846032, 0.4536094469153968),\n",
       " (43, 0.0, 0.0),\n",
       " (84, 0.0, 0.0),\n",
       " (84, 0.0, 0.0),\n",
       " (225, 0.2345140548527991, 0.7231687951472008),\n",
       " (225, 0.1328559525573064, 0.8248268974426936),\n",
       " (225, 0.3554645728195341, 0.6022182771804658),\n",
       " (329, 0.0, 0.0),\n",
       " (329, 1.0174602, 0.0),\n",
       " (329, 0.0, 0.0),\n",
       " (219, 0.0, 0.0),\n",
       " (219, 0.0, 0.0),\n",
       " (347, 0.0, 0.0),\n",
       " (347, 0.0, 0.0),\n",
       " (347, 0.0, 0.0),\n",
       " (380, 0.0, 0.0),\n",
       " (380, 0.0, 0.0),\n",
       " (380, 0.0, 0.0),\n",
       " (380, 0.0, 0.0),\n",
       " (64, 0.0, 0.0),\n",
       " (64, 0.0, 0.0),\n",
       " (64, 0.0, 0.0),\n",
       " (53, 0.0, 0.0),\n",
       " (53, 0.4497810552774128, 0.6382769447225871),\n",
       " (53, 0.0, 0.0),\n",
       " (53, 0.0, 0.0),\n",
       " (262, 0.0, 0.0),\n",
       " (262, 0.0, 0.0),\n",
       " (94, 0.0, 0.0),\n",
       " (94, 0.0, 0.0),\n",
       " (94, 0.0, 0.0),\n",
       " (94, 0.0, 0.0),\n",
       " (106, 0.0, 0.0),\n",
       " (106, 0.0, 0.0),\n",
       " (203, 0.0, 0.0),\n",
       " (203, 0.0, 0.0),\n",
       " (203, 1.08491811413713, 0.52829038586287),\n",
       " (254, 0.0, 0.0),\n",
       " (254, 0.0, 0.0),\n",
       " (244, 0.0, 0.0),\n",
       " (244, 0.0, 0.0),\n",
       " (244, 0.8485601127156568, 0.4925442872843433),\n",
       " (264, 0.0, 0.0),\n",
       " (264, 0.0, 0.0),\n",
       " (264, 0.0, 0.0),\n",
       " (264, 0.4731175773144764, 0.4523300226855236),\n",
       " (264, 0.0, 0.0),\n",
       " (142, 0.1893765658599842, 0.7476233341400158),\n",
       " (142, 0.0, 0.0),\n",
       " (160, 0.0, 0.0),\n",
       " (160, 0.0, 0.0),\n",
       " (160, 0.0, 0.0),\n",
       " (160, 0.0, 0.0),\n",
       " (160, 0.0, 0.0),\n",
       " (81, 0.0, 0.0),\n",
       " (357, 0.0, 0.0),\n",
       " (357, 0.0, 0.0),\n",
       " (305, 1.02162424605575, 0.2263381539442502),\n",
       " (100, 0.0, 0.0),\n",
       " (100, 0.0, 0.0),\n",
       " (100, 0.0, 0.0),\n",
       " (68, 0.0, 0.0),\n",
       " (154, 0.0, 0.0),\n",
       " (428, 2.2659641184936, 1.4023903815064),\n",
       " (428, 0.0, 0.0),\n",
       " (428, 0.0, 0.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5327486.0000, 5806657.5000, 8008878.0000, 4447922.0000, 4476182.0000,\n",
       "        4148849.7500, 5517874.5000, 4093083.7500, 5503929.0000, 6678124.5000,\n",
       "        6169298.0000, 6016802.0000, 3776196.7500, 4889560.5000, 9019005.0000,\n",
       "        5473608.5000, 6333264.0000, 5981333.5000, 5266115.0000, 5558643.0000,\n",
       "        3591988.7500, 4942362.0000, 7957057.5000, 5530094.0000, 4311635.5000,\n",
       "        7956750.5000, 4305153.0000, 4951033.5000, 4091515.0000, 4544701.5000,\n",
       "        9660567.0000, 4609254.5000], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = trainloop.data_loader\n",
    "x,y = next(iter(data_loader))\n",
    "x = x.to('cuda')\n",
    "y =y.to('cuda')\n",
    "guide_model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating:   0%|          | 0/328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 120/1000 [23:20<2:51:10, 11.67s/it]\n",
      "generating:   0%|          | 0/328 [23:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_sample_labelwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/projects/tf_diffusion/universal_guidance/universal_tools.py:503\u001b[0m, in \u001b[0;36mTrainLoop.create_sample_labelwise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# model_kwargs[\"y\"] = conditions_tensor\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m sampled_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_sample_loop_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_bs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperated_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconditions_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# if no guidance\u001b[39;49;00m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sampled_images):\n\u001b[1;32m    515\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([nucleotides[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(image\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m200\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)])\n",
      "File \u001b[0;32m/workspaces/projects/tf_diffusion/universal_guidance/../../re_design/Universal-Guided-Diffusion/Guided_Diffusion_Imagenet/guided_diffusion/gaussian_diffusion.py:947\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_sample_loop_operation\u001b[0;34m(self, model, shape, operated_image, operation, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress, eta)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03mGenerate samples from the model using DDIM.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03mSame usage as p_sample_loop().\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    946\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mddim_sample_loop_progressive_operation(\n\u001b[1;32m    948\u001b[0m     model,\n\u001b[1;32m    949\u001b[0m     shape,\n\u001b[1;32m    950\u001b[0m     operated_image,\n\u001b[1;32m    951\u001b[0m     operation,\n\u001b[1;32m    952\u001b[0m     noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    953\u001b[0m     clip_denoised\u001b[38;5;241m=\u001b[39mclip_denoised,\n\u001b[1;32m    954\u001b[0m     denoised_fn\u001b[38;5;241m=\u001b[39mdenoised_fn,\n\u001b[1;32m    955\u001b[0m     cond_fn\u001b[38;5;241m=\u001b[39mcond_fn,\n\u001b[1;32m    956\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs,\n\u001b[1;32m    957\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    958\u001b[0m     progress\u001b[38;5;241m=\u001b[39mprogress,\n\u001b[1;32m    959\u001b[0m     eta\u001b[38;5;241m=\u001b[39meta,\n\u001b[1;32m    960\u001b[0m ):\n\u001b[1;32m    961\u001b[0m     final \u001b[38;5;241m=\u001b[39m sample\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/projects/tf_diffusion/universal_guidance/../../re_design/Universal-Guided-Diffusion/Guided_Diffusion_Imagenet/guided_diffusion/gaussian_diffusion.py:1055\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_sample_loop_progressive_operation\u001b[0;34m(self, model, shape, operated_image, operation, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress, eta)\u001b[0m\n\u001b[1;32m   1053\u001b[0m t \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mtensor([i] \u001b[38;5;241m*\u001b[39m shape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1055\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_sample_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperated_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m out\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;66;03m# {\"sample\": sample, \"pred_xstart\": out[\"pred_xstart\"]}\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/projects/tf_diffusion/universal_guidance/../../re_design/Universal-Guided-Diffusion/Guided_Diffusion_Imagenet/guided_diffusion/gaussian_diffusion.py:791\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_sample_operation\u001b[0;34m(self, model, x, t, operated_image, operation, clip_denoised, denoised_fn, cond_fn, model_kwargs, eta)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    789\u001b[0m         x0\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m before_x \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m weights) \u001b[38;5;241m+\u001b[39m weights \u001b[38;5;241m*\u001b[39m x0\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m--> 791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    792\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    794\u001b[0m x0\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloop.create_sample_labelwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = torch.ones((30, 1, 4, 1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output,_ = torch.split(model_output, 1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgog_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
